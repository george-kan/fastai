{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist_full.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPC6JhopijGAJa1OrY7j1VA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/george-kan/fastai/blob/main/Mnist_full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y75OGILAIct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f9768a4-7d0f-47a0-c3ba-7ea5eebd42f9"
      },
      "source": [
        "#hide\r\n",
        "!pip install -Uqq fastbook\r\n",
        "import fastbook"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▌                               | 10kB 16.4MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 20.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 23.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40kB 20.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51kB 21.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 61kB 19.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 71kB 18.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 81kB 16.8MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 18.0MB/s eta 0:00:01\r\u001b[K     |████▌                           | 102kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 112kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 122kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 133kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 143kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 153kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 163kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 174kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 184kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 194kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 204kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 215kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 225kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 235kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 245kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 256kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 266kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 276kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 286kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 296kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 307kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 317kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 327kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 337kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 348kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 358kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 368kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 378kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 389kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 399kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 409kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 419kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 430kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 440kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 450kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 460kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 471kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 481kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 491kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 501kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 512kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 522kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 532kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 542kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 552kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 563kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 573kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 583kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 593kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 604kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 614kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 624kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 634kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 645kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 655kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 665kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 675kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 686kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 696kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 706kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 716kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 727kB 17.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 58.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 27.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 10.6MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYyxgCWABvkt"
      },
      "source": [
        "#hide\r\n",
        "from fastai.vision.all import *\r\n",
        "from fastbook import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgMfas_oBxXz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f5a1fb70-a8a2-482e-fdb0-2581dec5cb69"
      },
      "source": [
        "path = untar_data(URLs.MNIST)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg93Lx92B5Xi",
        "outputId": "2e39f2c4-0f9c-407a-9211-ea1894b94dca"
      },
      "source": [
        "(path/'training').ls()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [Path('/root/.fastai/data/mnist_png/training/4'),Path('/root/.fastai/data/mnist_png/training/9'),Path('/root/.fastai/data/mnist_png/training/1'),Path('/root/.fastai/data/mnist_png/training/5'),Path('/root/.fastai/data/mnist_png/training/2'),Path('/root/.fastai/data/mnist_png/training/7'),Path('/root/.fastai/data/mnist_png/training/6'),Path('/root/.fastai/data/mnist_png/training/0'),Path('/root/.fastai/data/mnist_png/training/3'),Path('/root/.fastai/data/mnist_png/training/8')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ich2jhhlFDdL",
        "outputId": "ff5d736b-3fb4-483a-bda3-8d28ffd6d587"
      },
      "source": [
        "folder = 'training/3'\r\n",
        "(path/folder).ls()\r\n",
        "(path/'testing').ls()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#6131) [Path('/root/.fastai/data/mnist_png/training/3/46061.png'),Path('/root/.fastai/data/mnist_png/training/3/12329.png'),Path('/root/.fastai/data/mnist_png/training/3/37729.png'),Path('/root/.fastai/data/mnist_png/training/3/54603.png'),Path('/root/.fastai/data/mnist_png/training/3/18059.png'),Path('/root/.fastai/data/mnist_png/training/3/59158.png'),Path('/root/.fastai/data/mnist_png/training/3/10454.png'),Path('/root/.fastai/data/mnist_png/training/3/37786.png'),Path('/root/.fastai/data/mnist_png/training/3/59398.png'),Path('/root/.fastai/data/mnist_png/training/3/28174.png')...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISW5WBUeEeCr"
      },
      "source": [
        "# Loading the data and creating lists of tensors \r\n",
        "train_x = []\r\n",
        "train_y = []\r\n",
        "test_x = []\r\n",
        "test_y = []\r\n",
        "for digit in range(10):\r\n",
        "    folder = 'training/' + str(digit)\r\n",
        "    new_inp = [tensor(Image.open(x)) for x in (path/folder).ls()]\r\n",
        "    #print(digit, len(new_inp))\r\n",
        "    train_x += new_inp\r\n",
        "    train_y += [digit]*len(new_inp)\r\n",
        "    test_folder = 'testing/' + str(digit)\r\n",
        "    test_inp = [tensor(Image.open(x)) for x in (path/test_folder).ls()]\r\n",
        "    test_x += test_inp\r\n",
        "    test_y += [digit]*len(test_inp)\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWVxlaYmFfY6",
        "outputId": "2fb47627-a3f1-4037-957c-e33aa51055c9"
      },
      "source": [
        "# Creating the dataloaders and the batches for SGD\r\n",
        "train_x_stacked = torch.stack(train_x).view(-1, 28*28).float()/255\r\n",
        "train_y_stacked = tensor(train_y).view(-1, 1)\r\n",
        "train_ds = list(zip(train_x_stacked, train_y_stacked))\r\n",
        "train_dl = DataLoader(train_ds, batch_size= 256, shuffle=True)\r\n",
        "\r\n",
        "test_x_stacked = torch.stack(test_x).view(-1, 28*28).float()/255\r\n",
        "test_y_stacked = tensor(test_y).view(-1, 1)\r\n",
        "test_ds = list(zip(test_x_stacked, test_y_stacked))\r\n",
        "test_dl = DataLoader(test_ds, batch_size=256)\r\n",
        "\r\n",
        "dls = DataLoaders(train_dl, test_dl)\r\n",
        "\r\n",
        "train_x_stacked.shape, train_y_stacked.shape, test_x_stacked.shape, test_y_stacked.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 784]),\n",
              " torch.Size([60000, 1]),\n",
              " torch.Size([10000, 784]),\n",
              " torch.Size([10000, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXv-qsNUGzjT"
      },
      "source": [
        "df = pd.DataFrame(torch.trunc(tensor(train_x[2000]).float()))\r\n",
        "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "qIXLYddVImKr",
        "outputId": "c9c51496-fc30-4d4b-ccfd-77321cd50135"
      },
      "source": [
        "# Simple approach using cross entropy loss\r\n",
        "def batch_accuracy(x, y):\r\n",
        "    preds = torch.argmax(x, 1)\r\n",
        "    correct = preds == y\r\n",
        "    return correct.float().mean()\r\n",
        "\r\n",
        "simple_net = nn.Sequential(\r\n",
        "            nn.Linear(28*28, 40),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(40, 40),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(40, 10)\r\n",
        ")\r\n",
        "loss = CrossEntropyLossFlat()\r\n",
        "learn = Learner(dls, simple_net, opt_func = SGD, loss_func = loss, metrics = batch_accuracy)\r\n",
        "learn.fit(10, 0.3)\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.355335</td>\n",
              "      <td>0.289755</td>\n",
              "      <td>0.838923</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.215078</td>\n",
              "      <td>0.283067</td>\n",
              "      <td>0.835513</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.172461</td>\n",
              "      <td>0.160481</td>\n",
              "      <td>0.872500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.136123</td>\n",
              "      <td>0.139557</td>\n",
              "      <td>0.879755</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.117577</td>\n",
              "      <td>0.134357</td>\n",
              "      <td>0.879063</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.103849</td>\n",
              "      <td>0.119845</td>\n",
              "      <td>0.884728</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.094595</td>\n",
              "      <td>0.100268</td>\n",
              "      <td>0.890200</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.089639</td>\n",
              "      <td>0.114602</td>\n",
              "      <td>0.884616</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.078251</td>\n",
              "      <td>0.123225</td>\n",
              "      <td>0.884156</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.073833</td>\n",
              "      <td>0.105466</td>\n",
              "      <td>0.889218</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qtZq-qaEwtg"
      },
      "source": [
        "# Manual implementation of the NN\r\n",
        "def init_params(size1, size2): return torch.randn(size1, size2).requires_grad_()\r\n",
        "\r\n",
        "def my_linear1(x): return x@w1 + b1\r\n",
        "\r\n",
        "def my_linear2(x): return x@w2\r\n",
        "\r\n",
        "def my_relu(x): return torch.maximum(tensor(0), x)\r\n",
        "#def my_relu(x): return torch.where(x < 0, 0.01*x, x)\r\n",
        "\r\n",
        "def my_softmax(x): \r\n",
        "    # Normalize the input to avoid numerical problems\r\n",
        "    x = x - torch.max(x, dim = 1).values.view(-1, 1)\r\n",
        "    return torch.exp(x) / torch.exp(x).sum(dim = 1).unsqueeze(1)\r\n",
        "\r\n",
        "def my_loss(x, y): \r\n",
        "    x = my_softmax(x)\r\n",
        "    y = y.view(-1, 1)\r\n",
        "    selection = torch.gather(x, 1, y)\r\n",
        "    #return (1-selection).mean()\r\n",
        "    return (-torch.log(selection + 1e-15)).mean()\r\n",
        "\r\n",
        "def my_model(x):\r\n",
        "    lay1 = my_linear1(x)\r\n",
        "    nonlin = my_relu(lay1)\r\n",
        "    #return nonlin\r\n",
        "    preds = my_linear2(nonlin)\r\n",
        "    return(preds)\r\n",
        "\r\n",
        "def update_grads(preds, y, params):\r\n",
        "    loss = my_loss(preds, y)\r\n",
        "    #print(loss)\r\n",
        "    loss.backward()\r\n",
        "    for p in params:\r\n",
        "        my_grad = p.grad\r\n",
        "        p.data -= my_grad*lr\r\n",
        "        #print(p.mean())\r\n",
        "        #print(my_grad.mean())\r\n",
        "        p.grad.zero_()\r\n",
        "\r\n",
        "def eval_batch():\r\n",
        "    preds_test = my_model(test_x_stacked)\r\n",
        "    positions = torch.max(preds_test, dim = 1).indices\r\n",
        "    return (positions == test_y_stacked.view(1,-1)).float().mean()\r\n",
        "\r\n",
        "w1 = init_params(28*28, 40)\r\n",
        "#w1 = init_params(28*28, 10)\r\n",
        "b1 = init_params(1, 40)\r\n",
        "#b1 = init_params(1, 1)\r\n",
        "w2 = init_params(40, 10)\r\n",
        "#b2 = init_params(1, 1)\r\n",
        "lr = 1\r\n",
        "params = w1, b1, w2#, b2"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMvyGGZSca7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea15b9e-d009-4e87-e4a4-61dc078ba7a8"
      },
      "source": [
        "for _ in range(40):\r\n",
        "  for x,y in train_dl:\r\n",
        "      preds = my_model(x)\r\n",
        "      update_grads(preds, y, params)\r\n",
        "  print(eval_batch())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.7329)\n",
            "tensor(0.8065)\n",
            "tensor(0.8448)\n",
            "tensor(0.8518)\n",
            "tensor(0.8649)\n",
            "tensor(0.9033)\n",
            "tensor(0.8995)\n",
            "tensor(0.8727)\n",
            "tensor(0.9178)\n",
            "tensor(0.9220)\n",
            "tensor(0.9044)\n",
            "tensor(0.9207)\n",
            "tensor(0.9237)\n",
            "tensor(0.9011)\n",
            "tensor(0.9225)\n",
            "tensor(0.9173)\n",
            "tensor(0.9344)\n",
            "tensor(0.9302)\n",
            "tensor(0.9323)\n",
            "tensor(0.9269)\n",
            "tensor(0.9322)\n",
            "tensor(0.9287)\n",
            "tensor(0.9398)\n",
            "tensor(0.9388)\n",
            "tensor(0.9320)\n",
            "tensor(0.9414)\n",
            "tensor(0.9280)\n",
            "tensor(0.9296)\n",
            "tensor(0.9405)\n",
            "tensor(0.9321)\n",
            "tensor(0.9245)\n",
            "tensor(0.9337)\n",
            "tensor(0.9394)\n",
            "tensor(0.9403)\n",
            "tensor(0.9418)\n",
            "tensor(0.9444)\n",
            "tensor(0.9444)\n",
            "tensor(0.9435)\n",
            "tensor(0.9469)\n",
            "tensor(0.9454)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}