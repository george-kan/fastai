{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist_full.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfWUjusifV98PrAFKuRJm2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/george-kan/fastai/blob/main/Mnist_full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y75OGILAIct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22ea7f3-425a-41a2-b634-9b1f721b30f6"
      },
      "source": [
        "#hide\r\n",
        "!pip install -Uqq fastbook\r\n",
        "import fastbook"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 727kB 5.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 37.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 45.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYyxgCWABvkt"
      },
      "source": [
        "#hide\r\n",
        "from fastai.vision.all import *\r\n",
        "from fastbook import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgMfas_oBxXz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8e1f7c74-2258-4e46-c28d-430459d0355c"
      },
      "source": [
        "path = untar_data(URLs.MNIST)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg93Lx92B5Xi",
        "outputId": "9bb1486c-635d-43c9-f745-01c9255ad785"
      },
      "source": [
        "(path/'training').ls()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [Path('/root/.fastai/data/mnist_png/training/8'),Path('/root/.fastai/data/mnist_png/training/3'),Path('/root/.fastai/data/mnist_png/training/4'),Path('/root/.fastai/data/mnist_png/training/0'),Path('/root/.fastai/data/mnist_png/training/6'),Path('/root/.fastai/data/mnist_png/training/9'),Path('/root/.fastai/data/mnist_png/training/5'),Path('/root/.fastai/data/mnist_png/training/7'),Path('/root/.fastai/data/mnist_png/training/1'),Path('/root/.fastai/data/mnist_png/training/2')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxZEr-63EpI6"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ich2jhhlFDdL",
        "outputId": "5b419a4a-16ff-4e2e-a098-a4d3a5156c59"
      },
      "source": [
        "folder = 'training/3'\r\n",
        "\r\n",
        "(path/folder).ls()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#6131) [Path('/root/.fastai/data/mnist_png/training/3/45599.png'),Path('/root/.fastai/data/mnist_png/training/3/46500.png'),Path('/root/.fastai/data/mnist_png/training/3/41404.png'),Path('/root/.fastai/data/mnist_png/training/3/10993.png'),Path('/root/.fastai/data/mnist_png/training/3/983.png'),Path('/root/.fastai/data/mnist_png/training/3/27840.png'),Path('/root/.fastai/data/mnist_png/training/3/17333.png'),Path('/root/.fastai/data/mnist_png/training/3/29097.png'),Path('/root/.fastai/data/mnist_png/training/3/40205.png'),Path('/root/.fastai/data/mnist_png/training/3/39761.png')...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdkzYQl9U4vG",
        "outputId": "731db779-c956-4671-b21b-57d924aa3d76"
      },
      "source": [
        "(path/'testing').ls()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [Path('/root/.fastai/data/mnist_png/testing/8'),Path('/root/.fastai/data/mnist_png/testing/3'),Path('/root/.fastai/data/mnist_png/testing/4'),Path('/root/.fastai/data/mnist_png/testing/0'),Path('/root/.fastai/data/mnist_png/testing/6'),Path('/root/.fastai/data/mnist_png/testing/9'),Path('/root/.fastai/data/mnist_png/testing/5'),Path('/root/.fastai/data/mnist_png/testing/7'),Path('/root/.fastai/data/mnist_png/testing/1'),Path('/root/.fastai/data/mnist_png/testing/2')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISW5WBUeEeCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f212845-76bf-4c74-8153-cb619d346f61"
      },
      "source": [
        "train_x = []\r\n",
        "train_y = []\r\n",
        "test_x = []\r\n",
        "test_y = []\r\n",
        "for digit in range(10):\r\n",
        "    folder = 'training/' + str(digit)\r\n",
        "    new_inp = [tensor(Image.open(x)) for x in (path/folder).ls()]\r\n",
        "    print(digit, len(new_inp))\r\n",
        "    train_x += new_inp\r\n",
        "    train_y += [digit]*len(new_inp)\r\n",
        "    test_folder = 'testing/' + str(digit)\r\n",
        "    test_inp = [tensor(Image.open(x)) for x in (path/test_folder).ls()]\r\n",
        "    test_x += test_inp\r\n",
        "    test_y += [digit]*len(test_inp)\r\n",
        "    "
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 5923\n",
            "1 6742\n",
            "2 5958\n",
            "3 6131\n",
            "4 5842\n",
            "5 5421\n",
            "6 5918\n",
            "7 6265\n",
            "8 5851\n",
            "9 5949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWVxlaYmFfY6",
        "outputId": "5e61821d-9f45-49ab-de4e-2ac8e9900705"
      },
      "source": [
        "train_x_stacked = torch.stack(train_x).view(-1, 28*28).float()/255\r\n",
        "train_y_stacked = tensor(train_y).view(-1, 1)\r\n",
        "train_ds = list(zip(train_x_stacked, train_y_stacked))\r\n",
        "train_dl = DataLoader(train_ds, batch_size= 256, shuffle=True)\r\n",
        "\r\n",
        "test_x_stacked = torch.stack(test_x).view(-1, 28*28).float()/255\r\n",
        "test_y_stacked = tensor(test_y).view(-1, 1)\r\n",
        "test_ds = list(zip(test_x_stacked, test_y_stacked))\r\n",
        "test_dl = DataLoader(test_ds, batch_size=256)\r\n",
        "\r\n",
        "dls = DataLoaders(train_dl, test_dl)\r\n",
        "\r\n",
        "train_x_stacked.shape, train_y_stacked.shape, test_x_stacked.shape, test_y_stacked.shape"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 784]),\n",
              " torch.Size([60000, 1]),\n",
              " torch.Size([10000, 784]),\n",
              " torch.Size([10000, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-VIu3M3IQtZ"
      },
      "source": [
        "train_x[2000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXv-qsNUGzjT"
      },
      "source": [
        "df = pd.DataFrame(torch.trunc(tensor(train_x[2000]).float()))\r\n",
        "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qIXLYddVImKr",
        "outputId": "0e446e86-2a93-446f-9739-bd1195095cf4"
      },
      "source": [
        "def batch_accuracy(x, y):\r\n",
        "    preds = torch.argmax(x, 1)\r\n",
        "    correct = preds == y\r\n",
        "    return correct.float().mean()\r\n",
        "\r\n",
        "simple_net = nn.Sequential(\r\n",
        "            nn.Linear(28*28, 40),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(40, 40),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(40, 10)\r\n",
        ")\r\n",
        "loss = CrossEntropyLossFlat()\r\n",
        "learn = Learner(dls, simple_net, opt_func = SGD, loss_func = loss, metrics = batch_accuracy)\r\n",
        "learn.fit(40, 0.3)\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.342673</td>\n",
              "      <td>0.273259</td>\n",
              "      <td>0.844673</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.211816</td>\n",
              "      <td>0.181899</td>\n",
              "      <td>0.866217</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.167797</td>\n",
              "      <td>0.272501</td>\n",
              "      <td>0.841799</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.144669</td>\n",
              "      <td>0.131778</td>\n",
              "      <td>0.883945</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.122090</td>\n",
              "      <td>0.131966</td>\n",
              "      <td>0.882782</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.103729</td>\n",
              "      <td>0.173585</td>\n",
              "      <td>0.869960</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.090275</td>\n",
              "      <td>0.111314</td>\n",
              "      <td>0.887486</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.082080</td>\n",
              "      <td>0.118197</td>\n",
              "      <td>0.885019</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.081032</td>\n",
              "      <td>0.115382</td>\n",
              "      <td>0.887778</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.074782</td>\n",
              "      <td>0.095189</td>\n",
              "      <td>0.893688</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.181758</td>\n",
              "      <td>0.122378</td>\n",
              "      <td>0.887509</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.076972</td>\n",
              "      <td>0.114644</td>\n",
              "      <td>0.889456</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.073115</td>\n",
              "      <td>0.110095</td>\n",
              "      <td>0.888346</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.065378</td>\n",
              "      <td>0.099027</td>\n",
              "      <td>0.892351</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.062296</td>\n",
              "      <td>0.094520</td>\n",
              "      <td>0.894666</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.059238</td>\n",
              "      <td>0.106094</td>\n",
              "      <td>0.892106</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.054569</td>\n",
              "      <td>0.096380</td>\n",
              "      <td>0.894320</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.055297</td>\n",
              "      <td>0.145524</td>\n",
              "      <td>0.879926</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.046641</td>\n",
              "      <td>0.100336</td>\n",
              "      <td>0.894466</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.045583</td>\n",
              "      <td>0.134076</td>\n",
              "      <td>0.885440</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.042079</td>\n",
              "      <td>0.166085</td>\n",
              "      <td>0.880832</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.041378</td>\n",
              "      <td>0.131471</td>\n",
              "      <td>0.884205</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.037829</td>\n",
              "      <td>0.146668</td>\n",
              "      <td>0.884043</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.036764</td>\n",
              "      <td>0.108064</td>\n",
              "      <td>0.892932</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.033823</td>\n",
              "      <td>0.108182</td>\n",
              "      <td>0.893567</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.034139</td>\n",
              "      <td>0.111316</td>\n",
              "      <td>0.893847</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.033840</td>\n",
              "      <td>0.149451</td>\n",
              "      <td>0.883782</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.028820</td>\n",
              "      <td>0.104968</td>\n",
              "      <td>0.893929</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.027739</td>\n",
              "      <td>0.107863</td>\n",
              "      <td>0.893964</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.024833</td>\n",
              "      <td>0.112261</td>\n",
              "      <td>0.894043</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.027664</td>\n",
              "      <td>0.114378</td>\n",
              "      <td>0.894182</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.022796</td>\n",
              "      <td>0.106783</td>\n",
              "      <td>0.896333</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.023173</td>\n",
              "      <td>0.114353</td>\n",
              "      <td>0.894298</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.020662</td>\n",
              "      <td>0.140610</td>\n",
              "      <td>0.887631</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.019938</td>\n",
              "      <td>0.111645</td>\n",
              "      <td>0.895559</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.022229</td>\n",
              "      <td>0.115378</td>\n",
              "      <td>0.893994</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.019230</td>\n",
              "      <td>0.147045</td>\n",
              "      <td>0.888413</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.016943</td>\n",
              "      <td>0.123266</td>\n",
              "      <td>0.894532</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.013873</td>\n",
              "      <td>0.117994</td>\n",
              "      <td>0.893964</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.012687</td>\n",
              "      <td>0.118565</td>\n",
              "      <td>0.893585</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihRBdQ3raaSC"
      },
      "source": [
        "x,y = dls.one_batch()\r\n",
        "learn.get_preds(dl = [(x,y)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5nfBLpaa2RL"
      },
      "source": [
        "??Learner"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c8vAU4RlEUh"
      },
      "source": [
        "w1 = init_params(28*28, 40)\r\n",
        "b1 = init_params(1, 1)\r\n",
        "w2 = init_params(40, 10)\r\n",
        "#b2 = init_params(1, 1)\r\n",
        "lr = 1\r\n",
        "params = w1, b1, w2#, b2"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qtZq-qaEwtg"
      },
      "source": [
        "def init_params(size1, size2): return torch.randn(size1, size2).requires_grad_()\r\n",
        "\r\n",
        "def my_linear1(x): return x@w1 + b1\r\n",
        "\r\n",
        "def my_linear2(x): return x@w2\r\n",
        "\r\n",
        "def my_relu(x): return torch.maximum(tensor(0), x)\r\n",
        "\r\n",
        "def my_softmax(x): \r\n",
        "    # Normalize the input to avoid numerical problems\r\n",
        "    x = x - torch.max(x, dim = 1).values.view(-1, 1)\r\n",
        "    return torch.exp(x) / torch.exp(x).sum(dim = 1).unsqueeze(1)\r\n",
        "\r\n",
        "def my_loss(x, y): \r\n",
        "    x = my_softmax(x)\r\n",
        "    y = y.view(-1, 1)\r\n",
        "    selection = torch.gather(x, 1, y)\r\n",
        "    #print(selection)\r\n",
        "    return (-torch.log(selection)).mean()\r\n",
        "\r\n",
        "def my_model(x):\r\n",
        "    lay1 = my_linear1(x)\r\n",
        "    nonlin = my_relu(lay1)\r\n",
        "    preds = my_linear2(nonlin)\r\n",
        "    return(preds)\r\n",
        "\r\n",
        "def update_grads(preds, y, params):\r\n",
        "    loss = my_loss(preds, y)\r\n",
        "    print(loss)\r\n",
        "    loss.backward()\r\n",
        "    for p in params:\r\n",
        "        my_grad = p.grad\r\n",
        "        p.data -= my_grad*lr\r\n",
        "        #print(p.mean())\r\n",
        "        #print(my_grad.mean())\r\n",
        "        p.grad.zero_()\r\n",
        "\r\n",
        "def eval_batch():\r\n",
        "    preds = my_model(test_x_stacked)\r\n",
        "    positions = torch.max(preds, dim = 1).indices\r\n",
        "    return (positions == test_y_stacked).float().mean()"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E63I1RG52Ntr",
        "outputId": "76621916-e8fe-40a2-8c33-79a908fb9806",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "my_loss(tensor([[1,2,3], [2,3,4]]).float(), tensor([[0],[2]]))"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4076)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvXhsriB2u1C",
        "outputId": "ca029acb-4e0b-4427-9bd8-d0de86ea0a32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "my_softmax(tensor([[1,2,3], [2,3,4]]).float())"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0900, 0.2447, 0.6652],\n",
              "        [0.0900, 0.2447, 0.6652]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJxuA6yO23Ms",
        "outputId": "da13eaab-9d78-4b84-8cfb-1c11c2bc051f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "-torch.log(tensor([0.0900, 0.6652])).mean()"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4078)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGAVoOkEJAUz"
      },
      "source": [
        "inputs, classes = next(iter(train_dl))  "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK4mmd573E-G"
      },
      "source": [
        "for i in range(40):\r\n",
        "  for x,y in train_dl:\r\n",
        "      #print(torch.unique(y, return_counts = True))\r\n",
        "      preds = my_model(x)\r\n",
        "      update_grads(preds, y, params)\r\n",
        "      #print('break')\r\n",
        "  #print(eval_batch())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}