{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 4 Questionnaire**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) How is a grayscale image represented on a computer? How about a color image?\n",
    "For a greyscale image, every pixel is a number where white corresponds to 0 and fully back corresponds to 255\n",
    "For a color image, every pixel is represented by 3 values on 3 arrays of the same size. They are Red, Green and Blue (RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) How are the files and folders in the MNIST_SAMPLE dataset structured? Why?\n",
    "There is one folder for the Train samples and one folder for the Validation/Test samples. The subfolders are split based on the number the pictures correspond to, so the subfolder 'threes' contains all the images of 3. \n",
    "This separation helps for creating the target variables and for separating Train and Test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Explain how the \"pixel similarity\" approach to classifying digits work\n",
    "The first part of the pixel similarity approach is to create the \"average three\" and the \"average seven\". Each pixel value of these averages corresponds to the mean of all the values of this particular pixel from all threes (or all sevens respectively). This is what we compare against in the classifier. \n",
    "\n",
    "The second part consists of establishing a measure of distance between the picture at hand and the average three (or the average seven). This is done by taking the mean of either the absolute difference of each pixel or of the squared difference of each pixel. \n",
    "\n",
    "After establishing the distance of the picture at hand from the averages, the classifier picks the value that is the smallest, that is if the distance of the test picture is smaller from the \"average three\" than it is from the \"average seven\" then the classifier selects 3 as its guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) What is a list comprehension? Create one now that selects odd numbers from a list and doubles them\n",
    "A list comprehension is a python operation that allows operations to be performed on each element of a list in a compactly written form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = list(range(30))\n",
    "[x*2 for x in my_list if x%2 != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) What is a rank 3 tensor?\n",
    "A rank 3 tensor is a tensor that has 3 dimensions or axes. When running tensor.shape this should return 3 numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) What is the difference between tensor rank and shape? How do you get the rank from the shape? \n",
    "The shape of a tensor tells the user how many entries correspond to each dimension of the tensor. For example a tensor that has a shape 3,7,4 is essentially a 3 dimensional matrix with 4 entries available in the first dimension, 7 entries for the second and 3 for the 3rd. The three numbers that are returned via the tensor.shape attribute correspond to the rank of the tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) What are RMSE and L1 norm?\n",
    "RMSE stands for root mean squared error and as the name suggests takes the error between prediction and target squares it, averages it and then takes the square root. It is also called the L2 norm.\n",
    "L1 norm is the mean of the absolute value of the difference between prediction and target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) How can you apply a calculation on thousands of numbers at once, many thousands of times faster than a Python loop? \n",
    "By using broadcasting. Python computes elementwise calculations very fast in an efficient manner in C. Broadcasting works in two scenarios:\n",
    "a) One of the two dimensions that differ are equal to 1 and this one is \"streched\" to match the other one\n",
    "b) The dimension is missing completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 5, 5],\n",
       "        [3, 3, 3],\n",
       "        [2, 2, 2]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "M_data = [[1., 2., 3.], [4., 5., 6]]\n",
    "M = torch.tensor(M_data)\n",
    "M.shape\n",
    "(M-1).shape\n",
    "# Here the following changes happened to the tensors:\n",
    "# 1 which is a tensor with dimensions (1) was stretched initially to match the first dimension of the M tensor (3)\n",
    "# As there is no second dimension for 1 it was just \"copied\" as many times as needed\n",
    "M2 = torch.tensor([[1,2], [4,6]])\n",
    "M2.shape\n",
    "#M + M2 This does not work as the dimensions are not aligned \n",
    "M3 = torch.tensor([[4], [2], [1]])\n",
    "M3.shape\n",
    "\n",
    "M4 = torch.tensor([1,1,1]).unsqueeze(0)\n",
    "M4.shape\n",
    "M3 + M4\n",
    "\n",
    "# Here what happened is the following: M3 has a shape of (3,1) and M4 has a shape of (1,3).\n",
    "# Starting from the 1st dimension M3 was expanded to have 3 columns so it became [[4,4,4], [2,2,2], [1,1,1]]\n",
    "# For the 2nd dimension M4 was expanded to have 3 rows so [[1,1,1], [1,1,1], [1,1,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Create a 3x3 tensor or array containing the numbers from 1 to 9. Double it. Select the bottom-right four numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 6],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myt = torch.tensor(range(1,10)).view(3,3)\n",
    "myt[1:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) What is broadcasting? (See question 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Are metrics generaly calculated using the training set or the validation set? Why?\n",
    "In general the validation set is used for the calculation of metrics. The reasoning is that the training set is used for finetuning weights/parameters and therefore using the metrics on the train set can lead the model to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) What is SGD?\n",
    "SGD stands for Stochastic Gradient Descent. The main difference between GD and SGD is that a single round of updating parameters in GD requires the gradient to be calculated on the full train dataset, while in SGD the updates are done incrementally based on batches where the gradient is being calculated. This results in faster improvements in the parameters and can overall be faster than GD. The drawback is that getting to the optimal point might not be so smooth and it could sometimes get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Why does SGD use mini-batches?\n",
    "Mini-batches are the compromise struck between using the full dataset (GD) which is slow, and using a single training example for updating the parameters, which might not be reflective of the correct direction the parameters should take or it might be too steep. Using a number of observations that is smaller than the total dataset but larger than a single observation is fast and gets us in the right direction in terms of optimization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) What are the seven steps in SGD for machine learning?\n",
    "- Initialise the parameters\n",
    "- Make predictions\n",
    "- Calculate loss\n",
    "- Calculate gradients\n",
    "- Update parameters\n",
    "- Repeat\n",
    "- Stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) How do we initialize the weights in a model?\n",
    "If no previous model is available for this task, just randomly and without using the same number for all the weights.\n",
    "Otherwise, we can use a pre-trained model for some of the weights (not the last layer usually as the pre-trained models were used for a different task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16) What is loss?\n",
    "Loss is a metric which quantifies how far our predictions are from the target we are aiming to achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17) Why can't we always use a higher learning rate?\n",
    "In some situations a higher learning rate can lead the model to diverge and move away from the optimal point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18) What is a gradient?\n",
    "Gradient is value of the derivative function at a specific point. We use the gradient of the loss function with respect to the parameters in order to understand the direction we have to push our parameters to. If the gradient is positive we push in the negative the direction for example, as we want the loss to become smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19) Do you need to know how to calculate gradinets yourself?\n",
    "No, as PyTorch does it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20) Why can't we use accuracy as a loss function?\n",
    "The loss function has to be a function that responds positively or negatively to small changes in the weights of the model. Accuracy is not such a function. In order for the accuracy to change our prediction for the training example has to change significantly. \n",
    "For example: In the MNIST_SAMPLE case the training examples are classified to 3 or 7 based on whether the prediction on them is above or below 0. A wrong prediction (a 3 classified as 7) will have a value negative value associated with it (let's say -7). If we change the weights so that the prediction in this training example moves in the correct direction (positive) and this results in a new value of -5, the accuracy will not change despite the fact that we are making progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21) Draw the sigmoid function. What is so special about its shape?\n",
    "The shape of the sigmoid is very smooth (good for derivatives) and it also restricts the values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22accf2dbe0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x): return 1/(1+torch.exp(-x))\n",
    "x = np.linspace(-5,5,100)\n",
    "y = sigmoid(torch.tensor(x))\n",
    "plt.plot(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22) What is the difference between a loss function and a metric?\n",
    "A loss function is a function used for the model to update the parameters incrementally. On the other hand a metric is a function used for humans so that they can assess how well the model performs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23) What is the function to calculate new weights using a learning rate?\n",
    "The step function. This function takes the old values of the parameters and \"pushes\" them into the oppoiste direction of the gradient times the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24) What does the DataLoader class do?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
