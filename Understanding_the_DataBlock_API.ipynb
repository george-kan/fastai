{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Understanding the DataBlock API",
      "provenance": [],
      "authorship_tag": "ABX9TyOYLkMAdkfKN/6wo/uCgIai",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/george-kan/fastai/blob/main/Understanding_the_DataBlock_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HS-tjaV5iJa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "359c81e5-e14e-4134-f8c0-6cedba1a678c"
      },
      "source": [
        "!pip install fastai --upgrade"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/50/0b81742909d433ef5b67b4417597b41cd37b38a073714bc83dc150c81b2f/fastai-2.2.7-py3-none-any.whl (193kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 18.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 102kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 112kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 122kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 133kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 143kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 153kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 163kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 174kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 184kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: spacy<3 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.0.0)\n",
            "Collecting torchvision<0.9,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/df/969e69a94cff1c8911acb0688117f95e1915becc1e01c73e7960a2c76ec8/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 328kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (19.3.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (20.9)\n",
            "Collecting fastcore<1.4,>=1.3.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/98/60404e2817cff113a6ae4023bc1772e23179408fdf7857fa410551758dfe/fastcore-1.3.19-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n",
            "\u001b[?25hCollecting torch<1.8,>=1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (54.0.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.8,>=1.7.0->fastai) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3->fastai) (3.7.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->fastai) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3->fastai) (3.4.1)\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision, fastcore, fastai\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "  Found existing installation: torchvision 0.9.0+cu101\n",
            "    Uninstalling torchvision-0.9.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.0+cu101\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "Successfully installed fastai-2.2.7 fastcore-1.3.19 torch-1.7.1 torchvision-0.8.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "fastai",
                  "torch",
                  "torchvision"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l7RHnS_5Wne"
      },
      "source": [
        "from fastai import *\n",
        "from fastai.vision.all import *"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMq8jKga-C9J"
      },
      "source": [
        "The aim of this notebook is to deep dive into the DataBlock class of fastai in order to bettern understand its components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UILrR1Rq-NBM"
      },
      "source": [
        "Let's start with a blank datablock.  \n",
        "Step 1: Initialisation outside of the init function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9AiI67uOaoY",
        "outputId": "13ea2b7d-7741-47d4-aed3-875ebd588d4e"
      },
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "path.ls()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [Path('/root/.fastai/data/mnist_sample/valid'),Path('/root/.fastai/data/mnist_sample/train'),Path('/root/.fastai/data/mnist_sample/labels.csv')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ts8GgviwZ7Xt",
        "outputId": "116d2b58-ee36-4fc0-f52a-4159294ddf64"
      },
      "source": [
        "pd.read_csv('/root/.fastai/data/mnist_sample/labels.csv')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train/3/7463.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train/3/21102.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train/3/31559.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train/3/46882.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train/3/26209.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14429</th>\n",
              "      <td>valid/7/1321.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14430</th>\n",
              "      <td>valid/7/8282.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14431</th>\n",
              "      <td>valid/7/1949.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14432</th>\n",
              "      <td>valid/7/3166.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14433</th>\n",
              "      <td>valid/7/7149.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14434 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    name  label\n",
              "0       train/3/7463.png      0\n",
              "1      train/3/21102.png      0\n",
              "2      train/3/31559.png      0\n",
              "3      train/3/46882.png      0\n",
              "4      train/3/26209.png      0\n",
              "...                  ...    ...\n",
              "14429   valid/7/1321.png      1\n",
              "14430   valid/7/8282.png      1\n",
              "14431   valid/7/1949.png      1\n",
              "14432   valid/7/3166.png      1\n",
              "14433   valid/7/7149.png      1\n",
              "\n",
              "[14434 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJIfJT4S5eoC"
      },
      "source": [
        "temp =  DataBlock(blocks = (ImageBlock, CategoryBlock))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTw6-HIr_OTq",
        "outputId": "e966620a-a15d-45ab-8bc8-87f0926c1ac0"
      },
      "source": [
        "temp.get_x, temp.get_items, temp.splitter, temp.get_y # All these methods are initialised to None by default"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnMKj7OP_YZJ",
        "outputId": "060ab8dd-3e77-46b5-fe14-72cbcf809a94"
      },
      "source": [
        "temp.blocks, temp.dl_type # By default it is assumed that both blocks (input and output) are generic TransformBlocks and the dl_type is a Transformed Dataloader (TfmdDL)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((fastai.data.block.TransformBlock, fastai.data.block.TransformBlock),\n",
              " fastai.data.core.TfmdDL)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffGjl06D6Vzj",
        "outputId": "fe12d22d-3024-476f-a5b1-aade4ec8a9e4"
      },
      "source": [
        "temp._methods # All possible methods together in a list"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['get_items', 'splitter', 'get_y', 'get_x']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRxmYYW1AlKy"
      },
      "source": [
        "Step 2: Variable initialisation inside the init function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVPxxQ7iAjX_",
        "outputId": "1273eca8-c468-475f-e666-1bf74ced28f2"
      },
      "source": [
        "temp.type_tfms \n",
        "#self.type_tfms = blocks.attrgot('type_tfms', L()) For both the input block and the output block we are initializing the type_tfms that are needed\n",
        "#Here we see two type tfms:\n",
        "# First is the PILBase.create of the ImageBlock which opens an image\n",
        "# The second part is the Categorize of the CategoryBlock which creates vocabulary for the Categories in the Categoryblock\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [[<bound method PILBase.create of <class 'fastai.vision.core.PILImage'>>],[Categorize -- {'vocab': None, 'sort': True, 'add_na': False}:\n",
              "encodes: (object,object) -> encodes\n",
              "decodes: (object,object) -> decodes\n",
              "]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seoxAXbZ-Wux",
        "outputId": "b147a61e-3c8e-4dfb-c89b-7fff54af18c8"
      },
      "source": [
        "#self.default_item_tfms  = _merge_tfms(*blocks.attrgot('item_tfms',  L()))\n",
        "temp.default_item_tfms  \n",
        "# By default from the TransformBlock there is a ToTensor transformation in the itemblock"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#1) [ToTensor:\n",
              "encodes: (PILMask,object) -> encodes\n",
              "(PILBase,object) -> encodes\n",
              "decodes: ]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk2QAn5PHLOB",
        "outputId": "2dd17a9f-05b9-4e3b-c67c-cdc0c8f8d6cf"
      },
      "source": [
        "#self.default_batch_tfms = _merge_tfms(*blocks.attrgot('batch_tfms', L()))\n",
        "temp.default_batch_tfms\n",
        "# By default the ImageBlock has a batch transformation IntToFloatTensor"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#1) [IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}:\n",
              "encodes: (TensorImage,object) -> encodes\n",
              "(TensorMask,object) -> encodes\n",
              "decodes: (TensorImage,object) -> decodes\n",
              "]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYdgZ7A_PBn_",
        "outputId": "316339e1-3cba-4834-bde9-b1749847c27a"
      },
      "source": [
        "inspect.signature(temp.dl_type.__init__)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Signature (self, dataset, bs=64, shuffle=False, num_workers=None, verbose=False, do_setup=True, pin_memory=False, timeout=0, batch_size=None, drop_last=False, indexed=None, n=None, device=None, persistent_workers=False, *, wif=None, before_iter=None, after_item=None, before_batch=None, after_batch=None, after_iter=None, create_batches=None, create_item=None, create_batch=None, retain=None, get_idxs=None, sample=None, shuffle_fn=None, do_batch=None)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6VzFztANyaZ",
        "outputId": "0232f779-adb7-414f-e8df-cd3b335467f7"
      },
      "source": [
        "#self.dataloaders = delegates(self.dl_type.__init__)(self.dataloaders)\n",
        "temp.dataloaders\n",
        "#self.dls_kwargs = merge(*blocks.attrgot('dls_kwargs', {}))\n",
        "temp.dls_kwargs"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJgeuiEeO_P_",
        "outputId": "2e7ccdde-0c32-4d88-f3bf-6f667d022e0e"
      },
      "source": [
        "#self.n_inp = ifnone(n_inp, max(1, len(blocks)-1))\n",
        "temp.n_inp\n",
        "#self.getters = ifnone(getters, [noop]*len(self.type_tfms))\n",
        "temp.getters"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<function fastai.imports.noop>, <function fastai.imports.noop>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tP0JEiRQlO_",
        "outputId": "301e7cdf-c622-41fa-d6d5-c8f4ee49eb4a"
      },
      "source": [
        "#if self.get_x:\n",
        "#           if len(L(self.get_x)) != self.n_inp:\n",
        "#               raise ValueError(f'get_x contains {len(L(self.get_x))} functions, but must contain {self.n_inp} (one for each input)\\n{self._msg}')\n",
        "#           self.getters[:self.n_inp] = L(self.get_x)\n",
        "# The idea here is that the input blocks can be more than 1 but the output block has to be 1. Therefore the n_inp is initialized to be max(1, len(blocks) - 1) where the last -1 is the output block\n",
        "temp.get_x, temp.get_y\n",
        "#if self.get_y:\n",
        "#    n_targs = len(self.getters) - self.n_inp\n",
        "#    if len(L(self.get_y)) != n_targs:\n",
        "#        raise ValueError(f'get_y contains {len(L(self.get_y))} functions, but must contain {n_targs} (one for each target)\\n{self._msg}')\n",
        "#    self.getters[self.n_inp:] = L(self.get_y)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgrt6OdA-DA5",
        "outputId": "88780924-8ddc-4af6-8c1b-31d41ede5f83"
      },
      "source": [
        "inspect.signature(temp.__init__)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Signature (blocks=None, dl_type=None, getters=None, n_inp=None, item_tfms=None, batch_tfms=None, *, get_items=None, splitter=None, get_y=None, get_x=None)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou-3LW47-zRQ",
        "outputId": "b54a65a4-15a6-40f9-dba6-d7b092390037"
      },
      "source": [
        "L(CategoryBlock(), TransformBlock()).attrgot('item_tfms') # Default transformation for everything is ToTensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [[<class 'fastai.data.transforms.ToTensor'>],[<class 'fastai.data.transforms.ToTensor'>]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK7kSoL7_CWw",
        "outputId": "472e1fc1-16a3-49e0-d64a-9b0430b092dc"
      },
      "source": [
        "L(CategoryBlock(), TransformBlock()).attrgot('batch_tfms')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [[],[]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em7sFOV4_P8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c019458d-fc63-44cd-c78a-b3f37c955165"
      },
      "source": [
        "L(CategoryBlock(), TransformBlock()).attrgot('dl_type')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [None,None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7QgpMhq9Vfv"
      },
      "source": [
        "# Cell\n",
        "@docs\n",
        "@funcs_kwargs\n",
        "class DataBlock():\n",
        "    \"Generic container to quickly build `Datasets` and `DataLoaders`\"\n",
        "    # These 4 lines are initializing the self parts\n",
        "    get_x=get_items=splitter=get_y = None\n",
        "    blocks,dl_type = (TransformBlock,TransformBlock),TfmdDL\n",
        "    _methods = 'get_items splitter get_y get_x'.split()\n",
        "    _msg = \"If you wanted to compose several transforms in your getter don't forget to wrap them in a `Pipeline`.\"\n",
        "    def __init__(self, blocks=None, dl_type=None, getters=None, n_inp=None, item_tfms=None, batch_tfms=None, **kwargs):\n",
        "        blocks = L(self.blocks if blocks is None else blocks) #Either defaults or the blocks provided\n",
        "        blocks = L(b() if callable(b) else b for b in blocks) #Functions (CategoryBlock) or someting else?\n",
        "        self.type_tfms = blocks.attrgot('type_tfms', L()) \n",
        "        self.default_item_tfms  = _merge_tfms(*blocks.attrgot('item_tfms',  L()))\n",
        "        self.default_batch_tfms = _merge_tfms(*blocks.attrgot('batch_tfms', L()))\n",
        "        for b in blocks:\n",
        "            if getattr(b, 'dl_type', None) is not None: self.dl_type = b.dl_type\n",
        "        if dl_type is not None: self.dl_type = dl_type\n",
        "        self.dataloaders = delegates(self.dl_type.__init__)(self.dataloaders)\n",
        "        self.dls_kwargs = merge(*blocks.attrgot('dls_kwargs', {}))\n",
        "\n",
        "        self.n_inp = ifnone(n_inp, max(1, len(blocks)-1))\n",
        "        self.getters = ifnone(getters, [noop]*len(self.type_tfms))\n",
        "        if self.get_x:\n",
        "            if len(L(self.get_x)) != self.n_inp:\n",
        "                raise ValueError(f'get_x contains {len(L(self.get_x))} functions, but must contain {self.n_inp} (one for each input)\\n{self._msg}')\n",
        "            self.getters[:self.n_inp] = L(self.get_x)\n",
        "        if self.get_y:\n",
        "            n_targs = len(self.getters) - self.n_inp\n",
        "            if len(L(self.get_y)) != n_targs:\n",
        "                raise ValueError(f'get_y contains {len(L(self.get_y))} functions, but must contain {n_targs} (one for each target)\\n{self._msg}')\n",
        "            self.getters[self.n_inp:] = L(self.get_y)\n",
        "\n",
        "        if kwargs: raise TypeError(f'invalid keyword arguments: {\", \".join(kwargs.keys())}')\n",
        "        self.new(item_tfms, batch_tfms)\n",
        "\n",
        "    def _combine_type_tfms(self): return L([self.getters, self.type_tfms]).map_zip(\n",
        "        lambda g,tt: (g.fs if isinstance(g, Pipeline) else L(g)) + tt)\n",
        "\n",
        "    def new(self, item_tfms=None, batch_tfms=None):\n",
        "        self.item_tfms  = _merge_tfms(self.default_item_tfms,  item_tfms)\n",
        "        self.batch_tfms = _merge_tfms(self.default_batch_tfms, batch_tfms)\n",
        "        return self\n",
        "\n",
        "    @classmethod\n",
        "    def from_columns(cls, blocks=None, getters=None, get_items=None, **kwargs):\n",
        "        if getters is None: getters = L(ItemGetter(i) for i in range(2 if blocks is None else len(L(blocks))))\n",
        "        get_items = _zip if get_items is None else compose(get_items, _zip)\n",
        "        return cls(blocks=blocks, getters=getters, get_items=get_items, **kwargs)\n",
        "\n",
        "    def datasets(self, source, verbose=False):\n",
        "        self.source = source                     ; pv(f\"Collecting items from {source}\", verbose)\n",
        "        items = (self.get_items or noop)(source) ; pv(f\"Found {len(items)} items\", verbose)\n",
        "        splits = (self.splitter or RandomSplitter())(items)\n",
        "        pv(f\"{len(splits)} datasets of sizes {','.join([str(len(s)) for s in splits])}\", verbose)\n",
        "        return Datasets(items, tfms=self._combine_type_tfms(), splits=splits, dl_type=self.dl_type, n_inp=self.n_inp, verbose=verbose)\n",
        "\n",
        "    def dataloaders(self, source, path='.', verbose=False, **kwargs):\n",
        "        dsets = self.datasets(source, verbose=verbose)\n",
        "        kwargs = {**self.dls_kwargs, **kwargs, 'verbose': verbose}\n",
        "        return dsets.dataloaders(path=path, after_item=self.item_tfms, after_batch=self.batch_tfms, **kwargs)\n",
        "\n",
        "    _docs = dict(new=\"Create a new `DataBlock` with other `item_tfms` and `batch_tfms`\",\n",
        "                 datasets=\"Create a `Datasets` object from `source`\",\n",
        "                 dataloaders=\"Create a `DataLoaders` object from `source`\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SabJpxxY9Nta"
      },
      "source": [
        "# Cell\n",
        "class TransformBlock():\n",
        "    \"A basic wrapper that links defaults transforms for the data block API\"\n",
        "    def __init__(self, type_tfms=None, item_tfms=None, batch_tfms=None, dl_type=None, dls_kwargs=None):\n",
        "        self.type_tfms  =            L(type_tfms)\n",
        "        self.item_tfms  = ToTensor + L(item_tfms)\n",
        "        self.batch_tfms =            L(batch_tfms)\n",
        "        self.dl_type,self.dls_kwargs = dl_type,({} if dls_kwargs is None else dls_kwargs)\n",
        "\n",
        "# Cell\n",
        "def CategoryBlock(vocab=None, sort=True, add_na=False):\n",
        "    \"`TransformBlock` for single-label categorical targets\"\n",
        "    return TransformBlock(type_tfms=Categorize(vocab=vocab, sort=sort, add_na=add_na))\n",
        "\n",
        "# Cell\n",
        "def MultiCategoryBlock(encoded=False, vocab=None, add_na=False):\n",
        "    \"`TransformBlock` for multi-label categorical targets\"\n",
        "    tfm = EncodedMultiCategorize(vocab=vocab) if encoded else [MultiCategorize(vocab=vocab, add_na=add_na), OneHotEncode]\n",
        "    return TransformBlock(type_tfms=tfm)\n",
        "\n",
        "# Cell\n",
        "def RegressionBlock(n_out=None):\n",
        "    \"`TransformBlock` for float targets\"\n",
        "    return TransformBlock(type_tfms=RegressionSetup(c=n_out))\n",
        "\n",
        "# Cell\n",
        "from inspect import isfunction,ismethod\n",
        "\n",
        "# Cell\n",
        "def _merge_grouper(o):\n",
        "    if isinstance(o, LambdaType): return id(o)\n",
        "    elif isinstance(o, type): return o\n",
        "    elif (isfunction(o) or ismethod(o)): return o.__qualname__\n",
        "    return o.__class__\n",
        "\n",
        "# Cell\n",
        "def _merge_tfms(*tfms):\n",
        "    \"Group the `tfms` in a single list, removing duplicates (from the same class) and instantiating\"\n",
        "    g = groupby(concat(*tfms), _merge_grouper)\n",
        "    return L(v[-1] for k,v in g.items()).map(instantiate)\n",
        "\n",
        "def _zip(x): return L(x).zip()\n",
        "\n",
        "\n",
        "# Cell\n",
        "def _short_repr(x):\n",
        "    if isinstance(x, tuple): return f'({\", \".join([_short_repr(y) for y in x])})'\n",
        "    if isinstance(x, list): return f'[{\", \".join([_short_repr(y) for y in x])}]'\n",
        "    if not isinstance(x, Tensor): return str(x)\n",
        "    if x.numel() <= 20 and x.ndim <=1: return str(x)\n",
        "    return f'{x.__class__.__name__} of size {\"x\".join([str(d) for d in x.shape])}'\n",
        "\n",
        "# Cell\n",
        "def _apply_pipeline(p, x):\n",
        "    print(f\"  {p}\\n    starting from\\n      {_short_repr(x)}\")\n",
        "    for f in p.fs:\n",
        "        name = f.name\n",
        "        try:\n",
        "            x = f(x)\n",
        "            if name != \"noop\": print(f\"    applying {name} gives\\n      {_short_repr(x)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"    applying {name} failed.\")\n",
        "            raise e\n",
        "    return x\n",
        "\n",
        "# Cell\n",
        "from .load import _collate_types\n",
        "\n",
        "def _find_fail_collate(s):\n",
        "    s = L(*s)\n",
        "    for x in s[0]:\n",
        "        if not isinstance(x, _collate_types): return f\"{type(x).__name__} is not collatable\"\n",
        "    for i in range_of(s[0]):\n",
        "        try: _ = default_collate(s.itemgot(i))\n",
        "        except:\n",
        "            shapes = [getattr(o[i], 'shape', None) for o in s]\n",
        "            return f\"Could not collate the {i}-th members of your tuples because got the following shapes\\n{','.join([str(s) for s in shapes])}\"\n",
        "\n",
        "# Cell\n",
        "@patch\n",
        "def summary(self: DataBlock, source, bs=4, show_batch=False, **kwargs):\n",
        "    \"Steps through the transform pipeline for one batch, and optionally calls `show_batch(**kwargs)` on the transient `Dataloaders`.\"\n",
        "    print(f\"Setting-up type transforms pipelines\")\n",
        "    dsets = self.datasets(source, verbose=True)\n",
        "    print(\"\\nBuilding one sample\")\n",
        "    for tl in dsets.train.tls:\n",
        "        _apply_pipeline(tl.tfms, get_first(dsets.train.items))\n",
        "    print(f\"\\nFinal sample: {dsets.train[0]}\\n\\n\")\n",
        "\n",
        "    dls = self.dataloaders(source, bs=bs, verbose=True)\n",
        "    print(\"\\nBuilding one batch\")\n",
        "    if len([f for f in dls.train.after_item.fs if f.name != 'noop'])!=0:\n",
        "        print(\"Applying item_tfms to the first sample:\")\n",
        "        s = [_apply_pipeline(dls.train.after_item, dsets.train[0])]\n",
        "        print(f\"\\nAdding the next {bs-1} samples\")\n",
        "        s += [dls.train.after_item(dsets.train[i]) for i in range(1, bs)]\n",
        "    else:\n",
        "        print(\"No item_tfms to apply\")\n",
        "        s = [dls.train.after_item(dsets.train[i]) for i in range(bs)]\n",
        "\n",
        "    if len([f for f in dls.train.before_batch.fs if f.name != 'noop'])!=0:\n",
        "        print(\"\\nApplying before_batch to the list of samples\")\n",
        "        s = _apply_pipeline(dls.train.before_batch, s)\n",
        "    else: print(\"\\nNo before_batch transform to apply\")\n",
        "\n",
        "    print(\"\\nCollating items in a batch\")\n",
        "    try:\n",
        "        b = dls.train.create_batch(s)\n",
        "        b = retain_types(b, s[0] if is_listy(s) else s)\n",
        "    except Exception as e:\n",
        "        print(\"Error! It's not possible to collate your items in a batch\")\n",
        "        why = _find_fail_collate(s)\n",
        "        print(\"Make sure all parts of your samples are tensors of the same size\" if why is None else why)\n",
        "        raise e\n",
        "\n",
        "    if len([f for f in dls.train.after_batch.fs if f.name != 'noop'])!=0:\n",
        "        print(\"\\nApplying batch_tfms to the batch built\")\n",
        "        b = to_device(b, dls.device)\n",
        "        b = _apply_pipeline(dls.train.after_batch, b)\n",
        "    else: print(\"\\nNo batch_tfms to apply\")\n",
        "\n",
        "    if show_batch: dls.show_batch(**kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}